<!DOCTYPE html>
<html lang="pt-br">

<head>
	<meta charset="utf-8" />
	<meta name="author" content="Humberto Lidio Antonelli" />
	<title>Questão 01</title>
</head>

<body>
	<h1>Especialistas imitam vozes e driblam 'reconhecimento de fala'</h1>
	<p><img src="questao01.jpg" width="200px"> Dois especialistas em segurança da Salesforce apresentaram resultados de
		uma pesquisa que expôs a fragilidade de sistemas de "reconhecimento" ou "autenticação" por voz. A dupla, formada
		por John Seymour e Azeem Aqil, descobriu que é possível "treinar" um software para gerar falas de outra pessoa
		com apenas dez minutos de gravações da voz da vítima. Gerando sons semelhantes à fala da vítima, um hacker
		poderia criar uma voz impostora para dar qualquer comando a um sistema controlado por voz.</p>

	<p>A pesquisa foi apresentada na conferência de segurança Black Hat em Las Vegas, nos Estados Unidos, na
		quinta-feira (9). A conclusão dos especialistas é que sistemas controlados por voz são inseguros.</p>
	<p><strong>Fonte: </strong><a
			href="https://g1.globo.com/economia/tecnologia/blog/altieres-rohr/post/2018/08/13/especialistas-imitam-vozes-e-driblam-reconhecimento-de-fala.ghtml">https://g1.globo.com/economia/tecnologia/blog/altieres-rohr/post/2018/08/13/especialistas-imitam-vozes-e-driblam-reconhecimento-de-fala.ghtml</a>

</body>

</html>